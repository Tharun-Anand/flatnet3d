{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainLoader import *\n",
    "import torchvision.transforms as transforms\n",
    "import itertools\n",
    "import logging\n",
    "import itertools\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data/salman/Lensless3D/data/'\n",
    "file_dir = '/media/data/salman/Lensless3D/files/'\n",
    "dataset_dir = data_dir + 'raw_data/FlyingThings3D_subset/'\n",
    "#data_dict_psf = mat73.loadmat('psfs_save_magfs.mat')\n",
    "#psfs = data_dict_psf['psfs'][:,:,:,-25:][::2,::2]\n",
    "\n",
    "def show_figure(image1, title1, mode=\"single\", image2=None, title2=None, save=False, img_name=None, cmap='gray'):\n",
    "    \n",
    "    if mode=='single':\n",
    "        fig = plt.figure()\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image1, cmap=cmap)\n",
    "        \n",
    "    if mode=='single-colorbar':\n",
    "        fig, ax = plt.subplots()\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "\n",
    "        im1 = ax.imshow(image1, cmap=cmap)\n",
    "        ax.set_title(title1)\n",
    "\n",
    "        fig.colorbar(im1, cax=cax, orientation='vertical')\n",
    "        \n",
    "    elif mode=='comparison':\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        divider = make_axes_locatable(ax1)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "\n",
    "        im1 = ax1.imshow(image1, cmap=cmap)\n",
    "        ax1.set_title(title1)\n",
    "\n",
    "        fig.colorbar(im1, cax=cax, orientation='vertical')\n",
    "        \n",
    "        divider = make_axes_locatable(ax2)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "\n",
    "        im2 = ax2.imshow(image2, cmap=cmap)\n",
    "        ax2.set_title(title2)\n",
    "\n",
    "        fig.colorbar(im2, cax=cax, orientation='vertical')\n",
    "        fig.tight_layout(pad=1.0)\n",
    "        fig.show()\n",
    "        \n",
    "    if save:\n",
    "        fig.savefig(img_name)\n",
    "\n",
    "    \n",
    "from struct import *\n",
    "def load_pfm(file_path):\n",
    "    \"\"\"\n",
    "    load image in PFM type.\n",
    "    Args:\n",
    "        file_path string: file path(absolute)\n",
    "    Returns:\n",
    "        data (numpy.array): data of image in (Height, Width[, 3]) layout\n",
    "        scale (float): scale of image\n",
    "    \"\"\"\n",
    "    with open(file_path, encoding=\"ISO-8859-1\") as fp:\n",
    "        color = None\n",
    "        width = None\n",
    "        height = None\n",
    "        scale = None\n",
    "        endian = None\n",
    "    \n",
    "        # load file header and grab channels, if is 'PF' 3 channels else 1 channel(gray scale)\n",
    "        header = fp.readline().rstrip()\n",
    "        if header == 'PF':\n",
    "            color = True\n",
    "        elif header == 'Pf':\n",
    "            color = False\n",
    "        else:\n",
    "            raise Exception('Not a PFM file.')\n",
    "\n",
    "        # grab image dimensions\n",
    "        dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', fp.readline())\n",
    "        if dim_match:\n",
    "            width, height = map(int, dim_match.groups())\n",
    "        else:\n",
    "            raise Exception('Malformed PFM header.')\n",
    "\n",
    "        # grab image scale\n",
    "        scale = float(fp.readline().rstrip())\n",
    "        if scale < 0:  # little-endian\n",
    "            endian = '<'\n",
    "            scale = -scale\n",
    "        else:\n",
    "            endian = '>'  # big-endian\n",
    "\n",
    "        # grab image data\n",
    "        data = np.fromfile(fp, endian + 'f')\n",
    "        shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "        # reshape data to [Height, Width, Channels]\n",
    "        data = np.reshape(data, shape)\n",
    "        data = np.flipud(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    \"\"\"VGG/Perceptual Loss\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    conv_index : str\n",
    "        Convolutional layer in VGG model to use as perceptual output\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, conv_index: str = '22'):\n",
    "\n",
    "        super(VGG, self).__init__()\n",
    "        vgg_features = torchvision.models.vgg19(pretrained=False).features\n",
    "        modules = [m for m in vgg_features]\n",
    "        \n",
    "        if conv_index == '22':\n",
    "            self.vgg = nn.Sequential(*modules[:8])\n",
    "        elif conv_index == '54':\n",
    "            self.vgg = nn.Sequential(*modules[:35])\n",
    "\n",
    "        vgg_mean = (0.485, 0.456, 0.406)\n",
    "        vgg_std = (0.229, 0.224, 0.225)\n",
    "        #self.sub_mean = common.MeanShift(rgb_range, vgg_mean, vgg_std)\n",
    "        self.vgg.requires_grad = False\n",
    "\n",
    "    def forward(self, sr: torch.Tensor, hr: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute VGG/Perceptual loss between Super-Resolved and High-Resolution\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sr : torch.Tensor\n",
    "            Super-Resolved model output tensor\n",
    "        hr : torch.Tensor\n",
    "            High-Resolution image tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : torch.Tensor\n",
    "            Perceptual VGG loss between sr and hr\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def _forward(x):\n",
    "            #x = self.sub_mean(x)\n",
    "            x = x.cpu()\n",
    "            x = self.vgg(x)\n",
    "            return x\n",
    "            \n",
    "        vgg_sr = _forward(sr)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            vgg_hr = _forward(hr.detach())\n",
    "\n",
    "        loss = F.mse_loss(vgg_sr, vgg_hr)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "## AIF metrics; gt, recon must be scaled from 0-1, dim:(128, 128, 3)\n",
    "\n",
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "\n",
    "def PSNR(gt, recon):\n",
    "    mse = np.mean((gt - recon) ** 2)\n",
    "    if(mse == 0): \n",
    "        return 100\n",
    "    max_pixel = 1.0\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def SSIM(gt, recon):\n",
    "    return ssim(gt, recon, multichannel=True)\n",
    "\n",
    "def LPIPSval(gt, recon):\n",
    "    gt = torch.from_numpy(gt.transpose(2, 0, 1).reshape(1, 3, 128, 128)).type(torch.float32)\n",
    "    recon = torch.from_numpy(recon.transpose(2, 0, 1).reshape(1, 3, 128, 128)).type(torch.float32)\n",
    "    return loss_fn_alex(gt, recon).item()\n",
    "    \n",
    "## Depth metrics\n",
    "\n",
    "def RMSE(gt, recon):\n",
    "    mse = np.mean((gt - recon) ** 2)\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 13\n",
    "train_dataset = TrainDataset('/home/sushanth/psf_captures/','/mnt/data/salman/LenslessDesign/datasets/FlyingThings3D/FlyingThings3D_subset/val/')\n",
    "train_dl = DataLoader(train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet2 import UNet\n",
    "device = 'cuda:1'\n",
    "model = UNet(in_channels=12*3,\n",
    "              out_channels=4,\n",
    "              in_layer='filter',\n",
    "              device = device,\n",
    "              batch_size = 2,\n",
    "              n_blocks=5,\n",
    "              start_filts = 64,\n",
    "              attention = True,\n",
    "              activation=nn.ELU(),\n",
    "              normalization='batch',\n",
    "              conv_mode='same',\n",
    "              out_layer='linear',\n",
    "              dim=2).to(device)\n",
    "#model = nn.DataParallel(model).to(device)\n",
    "\n",
    "criterion1 = VGG()\n",
    "#criterion2 = nn.CrossEntropyLoss()\n",
    "criterion2=nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "n_epochs = 50\n",
    "\n",
    "checkpoint = torch.load('/home/sushanth/test_codes/new_chkpoints_50.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda:1'\n",
    "for epoch in range(1, 150):\n",
    "    # Training loop\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    batch_limit = 200\n",
    "    limited_batches = itertools.islice(train_dl, batch_limit)\n",
    "    \n",
    "    for i, (meas, im, depth) in tqdm(enumerate(limited_batches), desc='Training Batch', leave=False):\n",
    "        im = F.pad(F.interpolate(im, [180, 180], mode='bilinear', align_corners=True), (6, 6, 6, 6))#Final shape B,192,192\n",
    "        depth = F.pad(F.interpolate(depth.unsqueeze(1), [180, 180], mode='nearest'), (6, 6, 6, 6)).squeeze(1)#Final shape B,192,192\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        yhat = model(meas.to(device).permute(0, 3, 1, 2).type(torch.float32))\n",
    "\n",
    "        x = criterion1((yhat[:, :3, ...]), im.to(device).type(torch.float32))\n",
    "        y = criterion2(yhat[:, 3:, ...].squeeze(1), depth.to(device).type(torch.float32)) \n",
    "        loss =  100*x + y\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "    avg_loss = epoch_loss / (i + 1)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
